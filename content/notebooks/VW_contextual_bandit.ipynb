{
 "metadata": {
  "name": "",
  "signature": "sha256:473cf9d8c03b7cc24188651e612ad5e503a8e1d1835ffde0fb97360786899222"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The task of contextual bandit is to find a policy $\\pi$ for deciding what action $a$ to take given a context $x$ or $a = \\pi(x)$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The goal is to find a policy which maximizes the reward $V^\\pi = E(r_{\\pi(x)})$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "one problem is how to measure the performance using offline data which was **not** collected with $\\pi$.\n",
      "Instead we have a sample of $(x,a,r_a)$ made by a different policy. For example a policy which uniformally sample from all available actions *a* regardless of *x*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Part 4 in [A Contextual-Bandit Approach to Personalized News Article Recommendation](http://www.research.rutgers.edu/~lihong/pub/Li10Contextual.pdf)\n",
      "describes how to test a bandit using offline data. But it was limited to a collection made with fixed (equal) probability for every arm $p(a) = 1/K$. This is a special case of *inverse propensity score* (IPS) method in which the probability $\\hat{p}(a|x)$ for every arm selection *a* is predicted based on the context *x* "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$\\hat{V}^\\pi_{\\mbox{IPS}} = \\hat{E}(\\frac{r_a I(\\pi(x)=a)}{\\hat{p}(a|x)})$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "where $\\hat{E}$ is averaging over all our samples in the offline data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A different approach is the *direct method* (DM) which predicts the reward *r* for every arm selection $\\hat{\\rho}_a(x)$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$\\hat{V}^\\pi_{\\mbox{DM}} = \\hat{E}(\\hat{\\rho}_{\\pi(x)}(x))$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[\"Doubly Robust Policy Evaluation and Learning\", by Miroslav Dudik, John Langford and Lihong Li. In ICML 2011.](http://arxiv.org/abs/1103.4601) combine the two methods using"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$\\hat{V}^\\pi_{\\mbox{DR}} = \\hat{E}(\\frac{(r_a - \\hat{\\rho}_a(x))I(\\pi(x)=a)}{\\hat{p}(a|x)} + \\hat{\\rho}_{\\pi(x)}(x))$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "VW"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[VW has a unit](https://github.com/JohnLangford/vowpal_wabbit/wiki/Contextual-Bandit-Example) that implements contextual bandit using offline data. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Evaluation a policy on offline data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is not clear to me what is the policy $\\pi$ being evaluated or optimized in VW (after all DR is just a way to evaluate it.)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The wiki gives the folowing example"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile /tmp/train.dat\n",
      "1:2:0.4 | a c  \n",
      "3:0.5:0.2 | b d  \n",
      "4:1.2:0.5 | a b c  \n",
      "2:1:0.3 | b c  \n",
      "3:1.5:0.7 | a d"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting /tmp/train.dat\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!vw -d /tmp/train.dat --cb 4 -f /tmp/cb.model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Num weight bits = 18\r\n",
        "learning rate = 0.5\r\n",
        "initial_t = 0\r\n",
        "power_t = 0.5\r\n",
        "final_regressor = /tmp/cb.model\r\n",
        "using no cache\r\n",
        "Reading datafile = /tmp/train.dat\r\n",
        "num sources = 1\r\n",
        "average    since         example     example  current  current  current\r\n",
        "loss       last          counter      weight    label  predict features\r\n",
        "*estimate* *estimate*                                                avglossreg last pred  last correct\r\n",
        "5.000000   5.000000          1      1.0    known        1        3   4.000000   0.000000   2.000000  \r\n",
        "2.500000   0.000000          2      2.0    known        2        3   2.125000   0.000000   0.500000  \r\n",
        "2.083333   1.666667          4      4.0    known        2        3   1.672500   0.000000   1.000000  \r\n",
        "\r\n",
        "finished run\r\n",
        "number of examples per pass = 5\r\n",
        "passes used = 1\r\n",
        "weighted example sum = 5\r\n",
        "weighted label sum = 0\r\n",
        "average loss = 1.69347\r\n",
        "best constant = 0\r\n",
        "total feature number = 16\r\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "prediciton"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "the policy from previous step `/tmp/cb.model` can be applied to new test data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile /tmp/test.dat\n",
      "1:2 3:5 4:1:0.6 | a c d  \n",
      "1:0.5 2:1:0.4 3:2 4:1.5 | c d "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting /tmp/test.dat\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!vw -t -d /tmp/test.dat -i /tmp/cb.model -p /tmp/out"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "only testing\r\n",
        "Num weight bits = 18\r\n",
        "learning rate = 10\r\n",
        "initial_t = 1\r\n",
        "power_t = 0.5\r\n",
        "predictions = /tmp/out\r\n",
        "using no cache\r\n",
        "Reading datafile = /tmp/test.dat\r\n",
        "num sources = 1\r\n",
        "average    since         example     example  current  current  current\r\n",
        "loss       last          counter      weight    label  predict features\r\n",
        "*estimate* *estimate*                                                avglossreg last pred  last correct\r\n",
        "1.000000   1.000000          1      1.0    known        4        4   0.318207   0.435902   1.000000  \r\n",
        "1.000000   1.000000          2      2.0    known        2        3   0.426955   0.268082   1.000000  \r\n",
        "\r\n",
        "finished run\r\n",
        "number of examples per pass = 2\r\n",
        "passes used = 1\r\n",
        "weighted example sum = 2\r\n",
        "weighted label sum = 0\r\n",
        "average loss = 1\r\n",
        "best constant = -1\r\n",
        "total feature number = 7\r\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat /tmp/out"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4.000000\r\n",
        "2.000000\r\n"
       ]
      }
     ],
     "prompt_number": 5
    }
   ],
   "metadata": {}
  }
 ]
}