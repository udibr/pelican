{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task of contextual bandit is to find a policy $\\pi$ for deciding what action $a$ to take given a context $x$ or $a = \\pi(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to find a policy which maximizes the reward $V^\\pi = E(r_{\\pi(x)})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one problem is how to measure the performance using offline data which was **not** collected with $\\pi$.\n",
    "Instead we have a sample of $(x,a,r_a)$ made by a different policy. For example a policy which uniformally sample from all available actions *a* regardless of *x*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 4 in [A Contextual-Bandit Approach to Personalized News Article Recommendation](http://www.research.rutgers.edu/~lihong/pub/Li10Contextual.pdf)\n",
    "describes how to test a bandit using offline data. But it was limited to a collection made with fixed (equal) probability for every arm $p(a) = 1/K$. This is a special case of *inverse propensity score* (IPS) method in which the probability $\\hat{p}(a|x)$ for every arm selection *a* is predicted based on the context *x* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat{V}^\\pi_{\\mbox{IPS}} = \\hat{E}(\\frac{r_a I(\\pi(x)=a)}{\\hat{p}(a|x)})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\hat{E}$ is averaging over all our samples in the offline data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A different approach is the *direct method* (DM) which predicts the reward *r* for every arm selection $\\hat{\\rho}_a(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat{V}^\\pi_{\\mbox{DM}} = \\hat{E}(\\hat{\\rho}_{\\pi(x)}(x))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[\"Doubly Robust Policy Evaluation and Learning\", by Miroslav Dudik, John Langford and Lihong Li. In ICML 2011.](http://arxiv.org/abs/1103.4601) combine the two methods using"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat{V}^\\pi_{\\mbox{DR}} = \\hat{E}(\\frac{(r_a - \\hat{\\rho}_a(x))I(\\pi(x)=a)}{\\hat{p}(a|x)} + \\hat{\\rho}_{\\pi(x)}(x))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[VW has a unit](https://github.com/JohnLangford/vowpal_wabbit/wiki/Contextual-Bandit-Example) that implements contextual bandit using offline data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation a policy on offline data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not clear to me what is the policy $\\pi$ being evaluated or optimized in VW (after all DR is just a way to evaluate it.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wiki gives the folowing example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/train.dat\n"
     ]
    }
   ],
   "source": [
    "%%writefile /tmp/train.dat\n",
    "1:2:0.4 | a c  \n",
    "3:0.5:0.2 | b d  \n",
    "4:1.2:0.5 | a b c  \n",
    "2:1:0.3 | b c  \n",
    "3:1.5:0.7 | a d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num weight bits = 18\r\n",
      "learning rate = 0.5\r\n",
      "initial_t = 0\r\n",
      "power_t = 0.5\r\n",
      "final_regressor = /tmp/cb.model\r\n",
      "using no cache\r\n",
      "Reading datafile = /tmp/train.dat\r\n",
      "num sources = 1\r\n",
      "average    since         example     example  current  current  current\r\n",
      "loss       last          counter      weight    label  predict features\r\n",
      "*estimate* *estimate*                                                avglossreg last pred  last correct\r\n",
      "5.000000   5.000000          1      1.0    known        1        3   4.000000   0.000000   2.000000  \r\n",
      "2.500000   0.000000          2      2.0    known        2        3   2.125000   0.000000   0.500000  \r\n",
      "2.083333   1.666667          4      4.0    known        2        3   1.672500   0.000000   1.000000  \r\n",
      "\r\n",
      "finished run\r\n",
      "number of examples per pass = 5\r\n",
      "passes used = 1\r\n",
      "weighted example sum = 5\r\n",
      "weighted label sum = 0\r\n",
      "average loss = 1.69347\r\n",
      "best constant = 0\r\n",
      "total feature number = 16\r\n"
     ]
    }
   ],
   "source": [
    "!vw -d /tmp/train.dat --cb 4 -f /tmp/cb.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prediciton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the policy from previous step `/tmp/cb.model` can be applied to new test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/test.dat\n"
     ]
    }
   ],
   "source": [
    "%%writefile /tmp/test.dat\n",
    "1:2 3:5 4:1:0.6 | a c d  \n",
    "1:0.5 2:1:0.4 3:2 4:1.5 | c d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only testing\r\n",
      "Num weight bits = 18\r\n",
      "learning rate = 10\r\n",
      "initial_t = 1\r\n",
      "power_t = 0.5\r\n",
      "predictions = /tmp/out\r\n",
      "using no cache\r\n",
      "Reading datafile = /tmp/test.dat\r\n",
      "num sources = 1\r\n",
      "average    since         example     example  current  current  current\r\n",
      "loss       last          counter      weight    label  predict features\r\n",
      "*estimate* *estimate*                                                avglossreg last pred  last correct\r\n",
      "1.000000   1.000000          1      1.0    known        4        4   0.318207   0.435902   1.000000  \r\n",
      "1.000000   1.000000          2      2.0    known        2        3   0.426955   0.268082   1.000000  \r\n",
      "\r\n",
      "finished run\r\n",
      "number of examples per pass = 2\r\n",
      "passes used = 1\r\n",
      "weighted example sum = 2\r\n",
      "weighted label sum = 0\r\n",
      "average loss = 1\r\n",
      "best constant = -1\r\n",
      "total feature number = 7\r\n"
     ]
    }
   ],
   "source": [
    "!vw -t -d /tmp/test.dat -i /tmp/cb.model -p /tmp/out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.000000\r\n",
      "2.000000\r\n"
     ]
    }
   ],
   "source": [
    "!cat /tmp/out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
